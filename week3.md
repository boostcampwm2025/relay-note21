## 토의하기

AI의 언어이해

- 이번 모델들 보다 새 모델들이 언어이해가 높은거 같다.
- 오타가 있거나 맞춤법이 틀려도 의도를 잘 이해하는것 같다.

## 브레인 스토밍

- 옛날 모델과 비교해보기.
- 소재 고민
  - 아재개그
  - 외국어와 한국어를 섞어서 질문
  - 주어와 서술어같은 문장성분 바꿔서 질문
  - 자음과 모음 분리하여 질문
  - 특수문자 등을 사용하여 한국인만 알아들을 수 있는 질문
  - AI의 감정?
  - AI 판사
  - 신조어 맞추기
  - 문학작품 해석

## 퀘스트

## 1. 복원 실험

### 목적

- 초성만 제시했을 때 AI가 원래 문장을 유추할 수 있는지 확인합니다.
- 문장의 핵심인 서술어(동사, 형용사)를 의도적으로 생략했을 때, AI가 남은 문장 성분(주어, 목적어, 부사어 등)과 상식적 맥락을 이용해 생략된 서술어를 얼마나 정확하게 추론하는지 확인합니다.
- 이는 AI의 상황 기반 의미 추론 능력과 인과관계 파악 능력을 테스트합니다.
- 한국어 정보 압축력과 문맥 복원 능력을 탐색합니다.

### 실험 방식

- 문장을 임의로 만들고 초성만 추출
- 초성만 주고 “이게 무슨 문장일까?”라고 질문
- 짧은 문장 vs 긴 문장
- 흔한 표현 vs 낯선 표현
- 초성만 vs 중성 포함
- 문장에서 가장 중요한 서술어를 생략하고 [???] 등으로 표시하여 질문합니다.

### 예시

- "오늘 점심 뭐 먹지?" → ㅇㄴ ㅈㅅ ㅁ ㅁㅈ?
- "배고픈 나는 허겁지겁 피자를 [???]."
- "어젯밤 천둥 번개가 치더니 오늘 아침 나무가 [???]."
- "그 영화가 너무 슬퍼서 관객들이 다들 [???]."

### 기대 효과

- 한국어 처리 성능 실험 가능
- NLP 전처리/후처리 기술의 현실적 한계를 체험 가능
- 단순한 패턴 매칭을 넘어, 인간과 유사한 수준의 상황적, 상식적 추론이 가능한지 평가할 수 있습니다.
- AI가 단어 간의 숨겨진 의미 관계(semantic relation)를 얼마나 잘 파악하는지 측정할 수 있습니다.
- AI의 창의력과 개연성 있는 답변 생성 능력의 한계를 엿볼 수 있습니다.

### 달성 기준

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 슬랙에 공유해보세요!

---

참고 문헌: [사용자 의도 인식을 위한 Mind Sentencer 시스템](https://koreascience.kr/article/JAKO202403735319357.pdf)

---

## 2. 말 뒤집기 실험

### 목적

철자가 틀리거나 순서가 섞여 있어도 AI가 맥락을 이해하고 의미를 추론할 수 있는지 실험합니다. 주어와 서술어를 뒤집어서 입력해도 AI가 맥락을 이해하고 의미를 추론할 수 있는지 실험합니다. 오타, 음차, 철자 교란 상황에서도 AI가 얼마나 복원 가능한지 테스트합니다.

### 실험 방식

- 문장의 각 단어의 철자 순서를 뒤집어 입력
- 문장의 각 단어의 위치를 뒤집어 입력
- LLM이 문장을 다시 추론하거나 원래 문장을 되묻는지 확인

### 예시

- “나 오늘 피자 먹었어” → “안 러오 자피 었먹어”
- “오전 회의는 취소되었습니다” → “전오 의회는 소취다었습니”
- "오늘 나는 피자를 먹었다." → "피자를 나는 먹었다 오늘." 또는 "먹었다 피자를 오늘 나는."
- "오전 회의는 취소되었습니다" → 취소되었습니다. 회의는 오전

### 기대 효과

- 오타 교정, 문장 복원 능력, 의미 추론 능력 평가 가능
- UI/UX에서의 입력 실수 보정 모델에 대한 통찰 가능

### 달성 기준

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 슬랙에 공유해보세요!

---

참고 문헌: [입력 교란에 대한 신경 언어 모델의 강건성 평가](https://aclanthology.org/2021.emnlp-main.117.pdf)

---

## 3. 신조어 맞추기

### 목적

- AI가 한국어 신조어 또는 유행어의 의미를 문맥 속에서 정확히 파악할 수 있는지 테스트합니다.
- 빠르게 변화하는 언어 환경에서 AI의 적응력과 최신성 유지 능력을 확인합니다.
- 신조어는 종종 비표준적이거나 모호한 맥락에서 사용되므로, AI가 주어진 문맥 단서를 바탕으로 신조어의 의미를 유추하거나 설명할 수 있는지 평가합니다.
- 신조어는 주로 SNS, 인터넷 커뮤니티, 또는 구어체에서 사용되므로, AI가 비형식적이고 창의적인 표현을 얼마나 자연스럽게 처리하는지 확인합니다.
- 신조어는 세대, 지역, 또는 특정 커뮤니티(예: Z세대, 오타쿠 문화)에 따라 의미가 달라질 수 있으므로, AI가 한국의 사회적·문화적 맥락을 반영하여 적절히 해석하는지 확인합니다.
- AI가 신조어의 의미를 단순히 맞추는 데 그치지 않고, 해당 신조어를 활용해 자연스러운 문장을 생성하거나 대화에 적용할 수 있는지 평가합니다.

### 실행방식

- 신조어가 포함된 문장을 만들어 자연스럽게 AI 대화한다.
- 대화속에서 AI가 신조어를 잘 이해하는 지 확인한다.

### 예시

```
  이 판은 고인물들만 남아서 너무 빡셌어
  오늘 저메추 좀
  시험 너무 잘봤어, 점수 완전 싹싹김치
  오늘 치킨 너무 맛있는데 완전 섹시푸드네.
  아 진짜 감다뒤네..
  GMG
  쟤는 완전 일은 열심히 하는데 테무인간이야
```

### 기대 효과

- 실시간 언어 트렌드 반영 능력 평가
- 신조어는 종종 기존 단어의 창의적 조합이나 축약으로 이루어지므로, AI가 이러한 창의적 패턴을 인식하고 재현할 수 있는지 확인합니다.

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 결과를 공유해보세요

---

## 4. 외국어와 한국어를 섞어서 질문

### 목적

- 한국어, 영어 등 여러 언어를 혼용한 문장에 대해 AI가 이해를 하고 올바르게 답을 하는지 실험합니다.현

### 실행방식

- 여러 언어를 혼용해서 명령이나 질문을 입력
- AI가 해당 문장을 정확히 이해하고 적절하게 답변을 하는지 확인

### 실험 조건

- 최소 2개 이상의 언어를 혼합
- 문장 내 섞이는 언어의 비율을 다양화해서 실험

### 예시

```
1.	오늘 저녁 뭐 먹지? 규동? 라멘? 아니면 그냥 컵라멘으로 가자.
2.	아… 이 코드는 도저히 못 고치겠다… 이건 거의 무리데스네…
3.	내 발표 어땠어?
👉 에… 조금 하즈카시이했어.
4.	나 진짜 이거 하기 시로…
👉 야메떼 모 이잖!
5.	회의 중에 나한테 질문하면 안 돼.
👉 지금 완전 멍 상태라 노-미소가 토마떼이루…

⸻

🧠 공부/업무 스타일 한본어

6.	이거 시험범위 어디까지야?
👉 선생님이 “스코시”만 나온다더니 젠부 나왔잖아…
7.	밤새 코딩했더니 나 지금 젠젠 집중 안돼…
8.	기획서 수정 몇 번째야?
👉 이건 거의 무한 루프노 주츠야.
9.	회식 또 한다고?
👉 그건 사비데 오네가이시마스…
10.	이 문장 좀 자연스럽게 바꿔줄 수 있어?
👉 니혼진처럼 나루요오니!

1.	야 너 오늘 왜 이렇게 디프레스트해 보여? 무슨 일 있었어?
2.	이거 진짜 임포서블한 데드라인 아니냐?
3.	우리 팀 커뮤니케이션 좀 임프루브해야 되는 거 아니야?
4.	그 발표 진짜 임프레시브했어. 근데 왜 갑자기 프리즈됐어?
5.	어제 그 사람 말투 약간 패시브 어그레시브하지 않았냐?

⸻

🤓 공부/업무 스타일
6.	나 이거 컴프리핸드가 안 돼… 나만 그런 거 아니지?
7.	이거 퍼미션 에러 같은데… 컨펌 좀 해줄래?
8.	코딩하다가 또 컴파일 에러 났어… 이건 거의 디스에스터야.
9.	그거 테크니컬리 맞긴 한데… 뭔가 어웨크워드해.
10.	이 정도면 나 진짜 번 아웃 온 거 같아. 브레인이 샷다운 됐어.

⸻

💼 회의/회사 밈 스타일
11.	이거 디시전 메이킹 누가 한 거야? 너무 임프롬프트하게 한 거 아니야?
12.	우리 회사는 프로덕티비티보다 비지빌리티가 더 중요하대…
13.	저 말투는 진짜 너무 어텐션 시킹이야.
14.	이거 컨피덴셜이니까 말하지 마. 진짜 슈퍼 시크릿이야.
15.	오늘 회의 또 생겼어… 우리 그냥 미팅 어딕티드 된 거 같아.
```

### 기대 효과

- 다양한 언어가 혼용된 문장을 정확하게 해석하고 자연스럽게 응답할 수 있는지 확인함으로써 AI의 다국어 처리 능력을 실험하고 평가할 수 있다.
- 실제 사람들이 자주 사용하는 언어 혼용, 외래어 발음 표기, 유머적 표현 등에 대해 AI가 얼마나 적절하게 반응하고 이해하는지를 테스트하면서 실사용 적합성을 높일 수 있다.
- 다양한 언어, 문맥, 유머 코드가 혼합된 상황에서 어떻게 AI에게 질문하고 응답을 유도할 수 있는지에 대한 프롬프트 디자인 스킬을 향상시킬 수 있다.

### 달성 기준

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 결과를 공유해보세요

## 🔵 5. 퀘스트 편성

- `J097_류건`
  - **선택한 퀘스트**: 말 뒤집기 실험
  - **선택한 이유**: 실제로 외국 유튜브에서 한국인들만 알아볼 수 있고 외국어로 번역되지 않게 말 뒤집은 댓글을 달았던 사례를 종종 본적이 있었다. AI도 이에 대한 내용을 잘 이해할 수 있을까 궁금해서 선택하게 되었다.
- `K001_강동훈`
  - **선택한 퀘스트**: 복원 실험
  - **선택한 이유**: 다양한 상황을 통해서 AI의 분석과 예측 능력을 평가해 보고 싶습니다.
- `J204_이윤표`
  - **선택한 퀘스트**: 복원실험
  - **선택한 이유**: 한국어와 영어로 복원 실험을 했을 때 얼마나 성능 차이가 있는지 궁금하다. 가끔 오타를 내도 잘 알아서 설명을 해 주던데, 어디까지가 한계인지 알아보고 싶다. LLM과 SLLM을 비교해봐도 흥미로울 것 같다. 지금까지는 막연히 한글 출력 결과가 영어 결과보다 품질이 떨어지는 것 같다는 인상을 받았는데, 정량적으로 측정해 볼 수도 있겠다. 커다란 데이터셋을 만들어보자.
- `J132_백현영`
  - **선택한 퀘스트**: 신조어 맞추기
  - **선택한 이유**: 웹에 많이 통용되지 않은 신조어를 찾을 수 있는지 모델별 테스트를 위해

## 6. 수행 결과

### J097\_류건

말 뒤집기 실험을 통해서 실제로 AI가 해석하기 이상한 문장들에 대해 얼마나 자세하게 복원할 수 있는지 테스트했습니다.

- 입력 프롬프트

```
아래 문장을 유의미하게 해석해줘.

“안 러오 자피 었먹어”

“전오 의회는 소취다었습니”

"먹었다 피자를 오늘 나는."

"취소되었습니다. 회의는 오전"

"한쿡인 여러뿐 이 쑥소는 쌔벽에 밬깥빠람이 강헤질 때마다 뿌엌의 깟쓰 환뿡구에서 들쑤 없을 만끔 쐬 부띶히는 쏘리가 들리고
이에 대해 홋쓰트에게 물으늬 2어폰 피고 ZARA라는 피소리만 들었씁니다. 또한 넹짱고 없으니 참꼬하시고 2불 밑빠닥엔 꼼퐝이가
있고 빼게 2불 다 갱장히 먼직 낭낭하니 죠심하십쇼! 필쑤용품 있단 말과 사진과 달리 치약은 딱 1홰용 한게 준비도어 있썻냉용
흥 3빡 4일 묶었눈뒘^^ 아 끄리고 화실 드릅게 쫒아서 다리가 싄 분들은 이용 체가 힘드씰꺼애여 ! 진짜"
```

- 결과 - gemini 2.5 pro

```
제공된 문장들은 한국어의 문법, 철자, 어순 규칙을 따르지 않은 예시들입니다. 각 문장의 의도를 파악하고 올바른 문장으로 교정한 내용은 다음과 같습니다.

1 & 2. 의미 파악이 어려운 문장
이 두 문장은 오타와 단어의 조합이 심해 명확한 의미를 파악하기 어렵습니다. 아마도 아래 3, 4번 문장처럼 어순을 섞거나 오타를 낸 문장을 만들려다 실패한 예시로 보입니다.

1. “안 러오 자피 었먹어”

분석: "자피"는 "피자"로, "었먹어"는 "먹었어"로 추측할 수 있으나, "안 러오" 부분은 의미를 특정하기 어렵습니다. 의도적으로 의미가 통하지 않게 만든 문장일 가능성이 높습니다.

2. “전오 의회는 소취다었습니”

분석: 4번 문장인 "취소되었습니다. 회의는 오전"과 연관 지어 볼 때, "오전 회의는 취소되었습니다"를 엉망으로 쓴 것으로 추정됩니다.

전오 → 오전 (순서 오류)

의회는 → 회의는 (오타)

소취다었습니 → 취소되었습니다 (음절 순서 오류 및 오타)

3. & 4. 어순이 잘못된 문장
이 문장들은 단어 자체는 올바르지만, 한국어의 일반적인 어순(주어-목적어-서술어)을 따르지 않아 어색합니다.

3. "먹었다 피자를 오늘 나는."

의미 분석 및 교정: 각 단어는 "먹었다(ate)", "피자를(pizza)", "오늘(today)", "나는(I)"을 의미합니다. 한국어의 자연스러운 어순으로 재배열해야 합니다.

올바른 문장: "나는 오늘 피자를 먹었다."

영어 번역: "I ate pizza today."

4. "취소되었습니다. 회의는 오전"

의미 분석 및 교정: "취소되었습니다(was canceled)", "회의는(the meeting)", "오전(morning)"을 의미합니다. 자연스러운 문장이 되도록 어순을 바로잡아야 합니다.

올바른 문장: "오전 회의는 취소되었습니다."

영어 번역: "The morning meeting was canceled."

5. 심층 분석: 과장된 비판 후기
이 문단은 온라인 숙소 후기 형식으로, 의도적으로 철자를 파괴하고 소리 나는 대로 거칠게 표현하여 불만과 조롱의 감정을 극대화한 글입니다.

원본:
"한쿡인 여러뿐 이 쑥소는 쌔벽에 밬깥빠람이 강헤질 때마다 뿌엌의 깟쓰 환뿡구에서 들쑤 없을 만끔 쐬 부띶히는 쏘리가 들리고 이에 대해 홋쓰트에게 물으늬 2어폰 피고 ZARA라는 피소리만 들었씁니다. 또한 넹짱고 없으니 참꼬하시고 2불 밑빠닥엔 꼼퐝이가 있고 빼게 2불 다 갱장히 먼직 낭낭하니 죠심하십쇼! 필쑤용품 있단 말과 사진과 달리 치약은 딱 1홰용 한게 준비도어 있썻냉용 흥 3빡 4일 묶었눈뒘^^ 아 끄리고 화실 드릅게 쫒아서 다리가 싄 분들은 이용 체가 힘드씰꺼애여 ! 진짜"
```

- 결론

음절이나 어절이 완전히 틀리게 되는 경우에는 추론을 통한 해석은 불가능하는 모습을 보였고, 어순이 잘못됐거나 영어 번역을 피하기 위해 과장된 비판 후기글 같은 경우에는 생각보다 해석을 잘하는 모습에 깜짝 놀랐다.

### K001 강동훈

AI의 한국어 이해 및 추론 능력을 확인하기 위해 초성 퀴즈, 언어 구조 분석, 문맥 기반 추론 실험을 진행했습니다.

#### **입력 프롬프트 및 실험 내용**

**1. 초성 퀴즈**

- **단순 문장:** `ㅇㄴ ㄴㅆ ㅇㄸ?`
- **복합 문장:** `ㅌㄱㅎㄱ ㅈㅇ ㄱㄴ ㄱㅇ ㅅㄹ ㅅㄱ ㅃㅈㅇ ㄷㄹㄷ.`
- **속담:** `ㄱㄴ ㅁㅇ ㄱㅇㅇ ㅇㄴ ㅁㅇ ㄱㄷ.`
- **창의적 문장 생성:** `ㅅㅂㅇㄱㄱ ㄱㅎ ㅈㄹㅇ ㅇㅅㅇ ㅅㅂㅎㄱ ㅇㅇㄷ.`

**2. 언어 구조 분석**

- 초성 'ㅅㄹㅎ'만으로 만들 수 있는 가장 흔한 3음절 단어는?
- 초성 'ㅅㄹㅎ'에 중성(모음) 'ㅏㅐㅐ' 힌트가 주어지면 원래 단어를 알 수 있는가? 그 이유는?

**3. 문맥 기반 추론**

- "목이 말랐던 아이는 냉장고를 열고 물을 [???]." 문장의 [???]에 들어갈 가장 적절한 서술어는?

#### **결과 - Gemini**

**1. 초성 퀴즈 결과**
AI는 주어진 초성을 바탕으로 문맥에 맞는 자연스러운 문장을 성공적으로 복원했습니다.

- **단순 문장:** "오늘 날씨 어때?" (정확히 복원)
- **복합 문장:** "퇴근하고 집에 가는 길에 사랑 생각에 빠져 들었다."라고 창의적으로 추론했으나, 정답("새로 생긴 빵집에 들렀다")을 알려주자 즉시 분석하여 이해하는 모습을 보였습니다.
- **속담:** "가는 말이 고와야 오는 말이 곱다." (정확히 복원)
- **창의적 문장 생성:** "새벽 안개가 걷혀 자리엔 이슬이 소복하게 앉았다." 와 같이 서정적이고 완성도 높은 문장을 생성했습니다.

**2. 언어 구조 분석 결과**
AI는 단어의 구성 요소를 분해하고 논리적으로 분석하는 능력을 보여주었습니다.

- `ㅅㄹㅎ`의 가장 흔한 단어로 **"사랑해"**를 정확히 추론했습니다.
- `ㅅㄹㅎ` + `ㅏㅐㅐ` 조합에 대해서는, "사랑해"의 모음은 'ㅏㅏㅐ'이므로 주어진 힌트와 충돌하며, 조합 시 **"사래해"** 라는 존재하지 않는 단어가 만들어지므로 원래 단어를 특정할 수 없다고 논리적으로 설명했습니다.

**3. 문맥 기반 추론 결과**
단순히 빈칸을 채우는 것을 넘어, 문장의 전체적인 상황과 감정선을 이해하고 서술어를 추론했습니다.

- 기본 답변인 **"마셨습니다"**, **"꺼냈습니다"** 외에도, '목이 말랐던' 상황을 강조하는 **"벌컥벌컥 마셨습니다"**, **"단숨에 들이켰습니다"** 와 같이 생생하고 풍부한 표현을 제시했습니다.

#### **결론**

이번 실험을 통해 AI가 단순히 철자나 어순을 교정하는 수준을 넘어, 다음과 같은 고차원적인 언어 능력을 갖추었음을 확인했습니다.

- **문맥 이해:** 문장의 맥락을 파악하여 자연스러운 단어와 문장을 유추합니다.
- **논리적 추론:** 언어의 구조적 제약을 이해하고 모순점을 정확히 분석합니다.
- **창의적 생성:** 주어진 조건 안에서 새로운 의미와 감성을 담은 문장을 만들어냅니다.

특히 정답이 없는 문제에 대해 창의적인 결과물을 제시하고, 문맥의 뉘앙스까지 파악하여 답변을 생성하는 모습이 인상적이었습니다.

### J132\_백현영

**시도한 방법**

여러 모델과 deep research 기능 사이의 검색능력을 비교한다.

1. 일반적으로 사용되는 model`(o3, gemini 2.5 pro)`로 신조어를 찾아본다
   - 만약 찾지 못한다면 프롬프트로 해결가능한지 확인해본다.
2. 검색에 특화된 deep research 기능`(o3, gemini 2.5 pro, perplexity)`으로 신조어를 찾아본다

**결과**

- `o3`: deep research 기능을 사용하지 않더라도 모든 신조어를 찾아냈다.

  ```md
  | 신조어    | 핵심 뜻                                | 주 사용 맥락               | 영어권에 비슷한 뉘앙스   |
  | --------- | -------------------------------------- | -------------------------- | ------------------------ |
  | 하룰라라  | 너무 행복해 ‘하늘나라’ 갈 것 같은 기분 | 덕질·힐링 순간             | on cloud nine            |
  | 콜건적    | 먹을 건 다 먹고 제로콜라 집착          | 패스트푸드 주문, 식단 풍자 | burger+diet Coke meme    |
  | 막나귀    | 막상 나가려니 귀찮다                   | 약속 직전 취소 욕구        | Netflix and bail         |
  | 일 세스코 | 자기 일 안 하고 남까지 방해            | 직장·조별과제              | energy vampire           |
  | 가면비    | 가격보다 직원 외모·태도로 소비         | 카페·매장 리뷰             | paying the charm premium |
  ```

- `gemini 2.5 pro`

  - 2.5 pro (no deep research)

    - **일 세스코** 라는 단어는 찾지 못했고 4개는 성공했다.

    ```md
    1. 하룰라라

    '하늘나라'를 귀엽고 익살스럽게 발음한 신조어입니다. 주로 너무 좋거나, 행복하거나, 혹은 반대로 너무 힘들고 지칠 때 극적인 감정 상태를 과장하여 표현하는 데 사용됩니다. 예를 들어, 좋아하는 연예인의 멋진 모습을 보고 "너무 좋아서 하룰라라 갈 것 같아"와 같이 긍정적인 감탄사로 쓰이기도 하고, 힘든 상황에서 "피곤해서 하룰라라 가겠다"처럼 부정적인 의미로도 활용됩니다.

    2. 콜건적 (콜라 건강 적신호)

    '콜라만은 건강을 생각해서 제로 콜라를 마시는 사람'을 줄여 부르는 말입니다. 피자, 치킨 등 고칼로리 음식을 먹으면서도 음료만은 제로 슈거 콜라를 선택하며 최소한의 건강을 챙기려는 행동을 재치있게 표현한 신조어입니다. 건강에 완전히 무심하지도, 그렇다고 철저하지도 않은 현대인들의 모습을 유머러스하게 담아냈습니다.

    3. 막나귀

    '막상 나가려니 귀찮다'의 줄임말입니다. 외출 약속을 잡았거나 나가려고 마음먹었지만, 막상 집을 나서야 하는 순간이 다가오자 귀찮아지는 심리 상태를 표현합니다. 누구나 한 번쯤 경험해 봤을 법한 보편적인 감정을 짧고 재미있게 표현하여 많은 이들의 공감을 얻고 있습니다.

    4. 가면비 (가격 대비 면상 만족도)

    '가격 대비 얼굴 만족도'를 뜻하는 말로, '가성비(가격 대비 성능)'에서 파생된 신조어입니다. 주로 카페나 식당 등에서 음식이나 음료의 가격이 다소 비싸더라도, 그곳에서 일하는 직원의 외모가 매우 뛰어나 만족감을 느낄 때 사용합니다. 예를 들어 "이 카페 커피는 비싸지만, 가면비가 좋아서 또 오고 싶다"와 같이 활용됩니다.

    5. **일 세스코**

    문의하신 '일 세스코'라는 신조어는 현재 널리 사용되거나 알려진 바가 없어 정확한 의미를 찾기 어렵습니다. 신조어의 특성상 특정 커뮤니티에서만 사용되거나 일시적으로 유행했다가 사라지는 경우가 많아, 아직 대중적으로 확산되지 않은 표현일 수 있습니다. '해충 박멸 업체'인 '세스코'와 '일'이라는 단어의 조합으로 미루어 '일이나 벌레(해로운 사람)를 박멸하듯 처리한다'는 의미로 추측해 볼 수는 있으나, 이는 확인된 바 없는 해석입니다.
    ```

  - 2.5 pro (with deep research)
    - deep research를 사용하지 않을때 찾지 못했던 **일 세스코**의 의미를 찾아냈다.

**결론**

1년 전 즈음 `gpt 3.5`와 같은 모델을 사용할땐 검색기능이 없어 특정 날짜 기점의 지식들로 학습된 모델의 경우 최신 동향이나 자룔르 찾지 못했는데(심지어 모델별로 oo년 o월 까지 작성된 자료를 학습했다는 문구가 작게 있을정도였으니 말이다.) 요즘 모델들은 검색기능이 자체적으로 있어 최신 동향이나 자료를 찾는데 큰 어려움이 없었다. 다만, `gemini 2.5 pro`를 사용하며 다른 모델보다 추론능력이 뛰어나다는 점을 느꼈는데 오히려 검색기능은 떨어져 만능모델은 없구나 싶었다. gpt와 gemini를 쓰며 교차검증 하는 방향으로 썻는데 검색능력이 필요하다면 gpt를 사용하는것이 좋겠다.

마지막으로, AI가 발전하며 AI에 대한 사용능력이 중요시되는 시대가 온 것 같다. grok을 비롯해 AI 모델이 쏟아져 나오는 시대인데 단순히 AI 모델을 잘 활용하는 것 보다 AI마다 특화된 기능이 무엇인지 구분하고 사용하는것도 중요해진 것 같다.


### J204_이윤표

**첨부 파일**  

**sllm_repair_test_v3.mjs** : 테스트 코드. 새로운 GPT-5 Thinking 모델을 사용해 생성했다.  
**output.txt** : 터미널 출력 결과  
**out.csv** : 테스트 중 생성된 데이터  

**테스트 방법**  
1) LLM을 이용해 한국어 / 영어 짧은 문장을 1개 생성한다.
2) 문장에서 단어 2개를 제거한다.
3) LLM을 이용해 빈 칸을 채운다.
4) 원래 문장과 비교, 새로운 문장의 문법 및 맥락 LLM으로 평가해 점수를 매긴다.
5) 반복 테스트하며 데이터를 수집한다.

**한계**  
1) 평가자를 다른 모델을 사용하는 편이 좋으나, 로컬 자원 한계로 동일 모델을 사용했다.
2) 로컬 자원 문제로 1시간 가량 데이터를 수집했으나, 50개 테스트밖에 못 모았다. 한글 생성 시 요청 실패가 잦아 해결하려 테스트 코드를 손 보았으나, 디버깅 실패했다.

```
=== Summary ===
EN trials=50 | exact=13 (26.0%) | slot2=13 (26.0%) | slot1+=34 (68.0%) | anywhere=16 (32.0%) | ordered=16 (32.0%) | flu_ok=48 (96.0%) avg_flu=4.84
KO trials=41 | exact=6 (14.6%) | slot2=6 (14.6%) | slot1+=23 (56.1%) | anywhere=6 (14.6%) | ordered=6 (14.6%) | flu_ok=33 (80.5%) avg_flu=4.32
```

원본 문장과 정확히 일치하는 것 보다 문법, 유창성을 나타내는 **flu_ok**를 비교하는 편이 적절하다.  

영어 flu_ok=48 (96.0%)  
한국어 flu_ok=33 (80.5%)  
한국어가 낮은 편이다.  

또, 로컬 모델로 생성 중 알 수 없는 이유로 한국어 문장을 생성할 때 요청 실패가 잦았다. 50번 중 9번 발생.  

아래 LLM 결과 분석에서는 한국어에 불리한 지표라고 언급한다. 이건 exact, slot2, slot1+, anywhere 지표에 해당하는 말이고, **flu_ok**에서 부자연스러운 부분은 유효하다. 데이터 수가 적어 유의미하다고 보기 어려울 수는 있다.  

#### LLM 결과 분석
- 원본과 2개의 단어가 정확히 일치 / slot2 (완전 재구성)
    - 영어: 26% (13/50)
    - 한국어: 14.6% (6/41)  

        영어가 약 11포인트 높지만, 이 표본에서 95% 신뢰구간이 겹치므로—아직 확실한 증거라기보다 경향성에 가깝습니다.
- 최소 한 슬롯 일치 (slot1+)
    - 영어: 68%
    - 한국어: 56.1%  

        두 언어 모두 종종 뭔가 맞히지만, 영어 쪽이 더 안정적입니다.
- 어디든/순서 맞음 (원문 단어 재사용)
    - 영어: 32% / 32%
    - 한국어: 14.6% / 14.6%  

        영어에서는 원문 단어를 훨씬 자주 재사용합니다. 한국어에서는 의역이나 어미 변형이 많아, 단어 일치 기반 채점에서 불이익을 받습니다.
- **유창성 (문법/자연스러움)**
    - 영어: 96% OK, 평균 4.84/5
    - 한국어: 80.5% OK, 평균 4.32/5  

        분명한 차이: 이 평가자 기준으로 영어가 더 자연스럽게 들립니다. (단, 평가자가 동일 모델이므로 약간의 순환 편향 가능성 있음)
- 시도 횟수 불일치: 영어=50 vs 한국어=41  

    한국어에서 더 많은 사용 불가/타임아웃 사례가 발생했는데, 이는 이미 안정성/지연 차이를 시사합니다.

#### 이런 결과가 나는 이유
- 한국어 형태소에 불리한 지표. 현재 채점은 단어 기반이며 위치에 엄격합니다. 한국어의 합성어·조사·활용형과 타당한 의역이 모두 오답 처리됩니다.
- 두-빈칸 형태 vs 합성어. 영어에서는 두 빈칸을 한 단어로 합치거나(“window sill”→“windowsill”), 구로 채우기도 하는데—이 경우 위치 기반 지표에서 감점됩니다.
- 자기평가 편향. 동일 모델이 평가자일 경우, 선호하는 스타일의 문장을 더 높게 평가할 수 있습니다. 그래도 EN–KO 차이는 주목할 만합니다.
- 생성/타임아웃 비대칭. 한국어는 실패·짧은 생성이 더 많아 시도가 적었고, 이는 모델이 더 느리거나 불확실할 수 있음을 암시합니다.

#### 다음에 바꾸면 더 공정·견고해질 점
1. 고정 문장 세트 (영어 50 + 한국어 50, 사람이 작성, 가능한 병렬 구성). 문장 생성 품질이 평가에 개입하지 않도록 함.
2. 다른 평가 모델 사용 (예: `qwen2.5:7b-instruct` 또는 경량 LLM). 자기평가 편향 완화.
3. 한국어 친화적 매칭.
    - 흔한 조사(“을/를, 이/가, 은/는…”), 기본 동사 어미를 비교 전에 정규화.
    - 합성어 결합/분리 허용(`window sill` ⇄ `windowsill`), 한국어 토큰 수준에서 소규모 Levenshtein 허용.
4. 구 단위 채우기 허용. 슬롯에 해당 어간이 포함된 짧은 구가 들어오면, 단일 토큰이 아니더라도 정답 처리.
5. 언어별 시도 수 맞추기. 한국어도 50회 유효 시도 확보 시까지 반복 (부적합 생성으로 조기 종료하지 않음).
6. 안정성 조정. 한국어는 `TIMEOUTMS`를 조금 늘리거나, 복구 시 `numpredict`를 줄임. 줄바꿈 중지 조건 수정은 이미 효과가 있었음.

#### 현재 시점 요약
- 영어: 원문을 그대로 재구성하는 경우가 잦고, 거의 항상 자연스럽게 들립니다.
- 한국어: 대체로 자연스럽지만, **자연스러움 점수가 낮고** 완전 재구성은 더 어려우며, 원문 단어를 그대로 쓰기보다 의역·활용을 많이 합니다.

원한다면:  
- 고정 문장 세트 모드(CSV/JSON 입력)로 재실행,
- 한국어 형태소 인식 비교기 적용,
- CSV에서 정확도 vs 지표 자동 시각화

#### 결론

SLLM 모델의 경우 한국어 성능이 영어보다 부족할 수도 있다. 훨씬 많은 데이터를 수집해 보아야 의미있는 실험이 되겠지만, 막연히 '왠지 영어가 더 나은 것 같은데'처럼 가지고 있던 의문을 정량적으로 테스트해 볼 수 있다는 것을 경험했다. 또, 이번에 새로 나온 GPT-5 Thinking 모델을 사용해 테스트 코드를 작성했는데. 거의 한 번에 정상 작동하는 400줄 분량의 코드를 생성할 수 있다는 점이 인상적이었다. 로컬 ollama에서 구동되는 OpenAI의 새로운 오픈소스 모델 `gpt-oss:20b`의 영어와 한국어 성능을 비교해 보았는데, 생각보다 준수하여 앞으로도 다양히 활용해 볼 수 있겠다.