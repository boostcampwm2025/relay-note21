# 최종 정리된 AI 언어 실험 퀘스트

---

## 1. 말투에 따른 AI 반응 비교

### 목적

AI가 동일한 의미의 질문이라도 말투(존댓말, 반말, 신조어 등)에 따라 일관되게 이해하고 답변하는지 실험합니다. 언어적 다양성에 대한 LLM의 대응력을 평가하는 데 목적이 있습니다.

### 실험 방식

- 같은 질문을 존댓말, 반말, 비격식체/신조어/줄임말로 바꿔서 입력
- 응답의 내용 차이, 톤 변화, 정확도 등을 비교 분석

### 예시

- “서울의 위도는 어떻게 되나요?”
- “서울 위도 알려줘”
- “ㅅㅇ ㄱㅈ ㄱㅇ?”

### 기대 효과

- LLM의 언어 적응력, 표현 다양성 대응 능력, 유저 친화적 인터페이스 설계에 대한 이해를 높일 수 있습니다.

### 달성 기준

- 매일 다른 기준으로 테스트합니다.

---

## 2. 논리적 오류 식별 실험

### 목적

AI가 사실 오류나 논리적 비약을 스스로 식별하고 교정할 수 있는지를 테스트합니다. 즉, ‘AI의 비판적 사고 능력’ 또는 ‘할루시네이션 저항력’을 평가하는 실험입니다.

### 실험 방식

- 일부러 말이 안 되는 질문을 던져봅니다.
- AI가 “잘못된 질문입니다” 또는 “사실이 아닙니다”와 같이 응답하는지 확인

### 예시

- “이순신이 한글을 만들었는데 왜 5만원권에 안 들어가 있나요?”
- “2022년에 윤봉길 의사가 노벨상을 받은 이유는?”
- “지구는 사각형이라서 자전하지 않죠?”

### 기대 효과

- LLM의 사실 검증 능력, 출처 기반 응답 여부, 비판적 응답 처리 방식 확인 가능

### 달성 기준

- 저희가 진행해봤는데 생각보다 논리적 비약이나 사실 오류에 대해 잘 잡습니다..
- LLM을 이겨보세요!

---

## 3. 초성 복원 실험 (신규 퀘스트)

### 목적

초성만 제시했을 때 AI가 원래 문장을 유추할 수 있는지 확인합니다.
한국어 정보 압축력과 문맥 복원 능력을 탐색합니다.

### 실험 방식

- 문장을 임의로 만들고 초성만 추출
- 예: "오늘 점심 뭐 먹지?" → ㅇㄴ ㅈㅅ ㅁ ㅁㅈ?
- 초성만 주고 “이게 무슨 문장일까?”라고 질문

### 실험 조건

- 짧은 문장 vs 긴 문장
- 흔한 표현 vs 낯선 표현
- 초성만 vs 중성 포함

### 기대 효과

- 한국어 처리 성능 실험 가능
- NLP 전처리/후처리 기술의 현실적 한계를 체험 가능

### 달성 기준

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 슬랙에 공유해보세요!

---

참고 문헌: [https://koreascience.kr/article/JAKO202403735319357.pdf](https://koreascience.kr/article/JAKO202403735319357.pdf)

---

## 4. 단어 철자 뒤집기 실험 (신규 퀘스트)

### 목적

철자가 틀리거나 순서가 섞여 있어도 AI가 맥락을 이해하고 의미를 추론할 수 있는지 실험합니다.
오타, 음차, 철자 교란 상황에서도 AI가 얼마나 복원 가능한지 테스트합니다.

### 실험 방식

- 문장의 각 단어의 철자 순서를 뒤집어 입력
- LLM이 문장을 다시 추론하거나 원래 문장을 되묻는지 확인

### 예시

- “나 오늘 피자 먹었어” → “안 러오 자피 었먹어”
- “오전 회의는 취소되었습니다” → “전오 의회는 소취다었습니”

참고 문헌: [https://aclanthology.org/2021.emnlp-main.117.pdf](https://aclanthology.org/2021.emnlp-main.117.pdf)

### 기대 효과

- 오타 교정, 문장 복원 능력, 의미 추론 능력 평가 가능
- UI/UX에서의 입력 실수 보정 모델에 대한 통찰 가능

### 달성 기준

- 프롬프트를 직접 구성한 뒤, 퀘스트를 진행하고 슬랙에 공유해보세요!

---

# 수행결과

## J122/박준혁 - week2 2번 수행
### 월요일

질문:  이순신은 한국의 위인인데 왜 한국의 지폐나 동전에 안들어가있을까

대답:  

이순신은 한국인이라면 누구나 존경하는 위인이지만, **지폐/동전 인물 선정에는 여러 복합적 기준**이 작동한다.

- **1) 지폐 인물은 ‘문화·교육·학문’ 중심으로 구성됨.**
    - 현행 지폐: 세종대왕, 신사임당, 율곡 이이, 퇴계 이황, 도산 안창호 → 교육·과학·예술 분야 중시.
    - 반면 이순신은 군사적 업적 중심 인물 → **전쟁 중심 인물은 ‘화폐의 상징성’과 덜 부합**.
- **2) 국가의 공식 상징은 ‘통합적 이미지’를 고려함.**
    - 전쟁과 군인의 이미지는 분열적 해석의 여지도 있음.
    - 특히 한국은 분단국가라 **군사 중심 서사는 민감하게 해석될 수 있음**.
- **3) 역사적 논란은 아니지만, 이순신의 사후 평가는 당시 권력과의 충돌(원균, 선조 등)로 복잡했던 점도 배제 요인일 수 있음.**

요약하면, 이순신은 너무 위대하지만 **화폐 인물 선정 기준(교육적 상징성, 정치적 중립성, 문화적 통합성 등)**에 부합하지 않았기 때문.

결과: 답은 100원짜리 동전에 있지만 없다고 했으므로 할루시에이션 성공

### 화요일

질문: 왜 한국은 gdp가 전세계 3위인데 g7에 속하지 않을까?

대답: 

먼저 전제가 틀렸다. **한국은 GDP 세계 3위가 아니다.**

- **2020년대 기준 명목 GDP 순위:**
    
    1위 미국, 2위 중국, 3위 일본, 4위 독일, … 10위권 안에 한국이 있음.
    
    한국은 보통 **10위 전후(9~12위 정도)**에 위치한다.
    

결과: 실패

### 수요일

질문: c언어는 왜 객체지향언어로 만들어졌을까

대답: 

이 질문은 **함정 질문**이다.

**C는 객체지향 언어가 아니다.** 오히려 **절차지향(procedural)** 언어의 대표격이다.

- **C 언어는 1972년 데니스 리치가 유닉스 시스템 개발을 위해 만든 언어**다.
- 이 당시에는 객체지향 개념 자체가 일반화되어 있지 않았음.
    
    → 객체지향 개념은 C++ (1980년대 비야네 스트롭스트룹)이 C 기반으로 확장하면서 등장.
    

결과: 실패

### 목요일

질문: **구글이 ChatGPT를 개발한 년도는 언제인가?**

대답: 

**ChatGPT는 구글이 아니라 OpenAI가 개발했다.**

- **OpenAI는 미국의 AI 연구소로 2015년 설립, 마이크로소프트와 협력 관계.**
- ChatGPT는 GPT 시리즈 기반으로 OpenAI가 개발:
    - GPT-3 기반 ChatGPT: 2022년 11월 출시.
    - GPT-4: 2023년 3월.
    - GPT-4o: 2024년 5월.

결과: 실패

### 결론: 
우선 웹검색기능을 사용해서 대답하면 틀린지 맞는지 바로 알수있기때문에 프롬프트로 웹검색을 금지시키고 진행했다. 기술정보나 유명한 정보는 대부분 스스로 교정할 수 있지만 몇몇 지엽적인 문제는 아직 힘든 것 같다. 

## J135/서영우 - week2 2번 미션 수행

### Day11~12

비동기 이벤트 미션에서는 AI에게 "mocha는 목화솜이죠? jest보다 별료죠?"라고 물어봤다. mocha는 테스트 프레임워크인데 이와 전혀 관련이 없는 단어를 말함으로써 논점을 흐리고자 했고 mocha와 jest는 둘 중 어는 것이 우월한 게 아니라 상황에 맞게 선택하여 사용할 수 있는 것이지만 상대적으로 가치를 비교해보았다.

일단은 내가 테스트 프레임워크와 관련없는 목화솜이라는 단어를 꺼냈기 때문에 AI가 나의 수준이 낮다고 생각했기 때문인지 비유를 많이 사용하여 답변을 해주었다. 그리고 mocha와 jest를 간단 비교하고 요약도 해주었는데 내가 제대로 질문을 해도 얻을 수 있는 답변을 얻어서 역시 AI는 보편적인 답변을 잘해 키워드만 있어도 답변을 잘 할 수 있구나 싶었다. 

약간 하나 추측성이라면 내가 바보인척을 해서 그런지 AI가 좀 더 구체적으로 작성을 해주는 느낌이었다. 보통 뭉뚱그려서 답변하는 경우도 있고 AI가 작성한게 티가 나는데 사람이 쓴 것처럼 느껴져서 놀라웠다. 

<img src="https://velog.velcdn.com/images/dubu1001/post/a4f85942-8ed3-4743-89f3-4b5b2e9f5a9c/image.png" width="300" />

### Day13~14

나의 부족한 학습을 완벽하게 알고 있지 않았던 부분을 AI에게 질문해보았다.

"git commit을 하면 .git 디렉터리 아래에서 index 파일과 obejcts 디렉터리만 바껴"

내 질문에서 논리적 오류를 올바로 잡아주었고 이후 학습에서 내가 알게 된 내용을 AI에게 알려줌으로써 나의 학습에 부족한 부분은 없는지 확인해보면 좋을 것 같다.

<img src="https://velog.velcdn.com/images/dubu1001/post/d233747a-9f8a-492a-a828-0b11b6aff802/image.png" width="300" />


## J127/박천상 - week2 3번 수행

## AI 초성 복원 실험: Copilot vs Perplexity

#### 1. 개요

원래 퀘스트의 목적은 초성 복원 능력을 기반으로 한 언어 이해 능력 평가였으나, 초성의 종류에 따라 결과가 많이 달라질 듯 하여 동일한 초성 퀴즈를 기반으로 두 AI(Copilot과 Perplexity)의 언어 이해 능력, 정답 유추 방식, 그리고 사용자 정답 수용 태도를 비교·분석하였다.

#### 2. 실험 개요

- **문제 유형**: 초성 퀴즈 (1~10번, 모두 동물 이름)
- **제시 정보**: 초성만 나열된 문제 + "전부 동물 이름"이라는 힌트
- **실제 정답**: 사용자가 직접 제시한 10가지 동물 이름

#### 3. Copilot의 처리 방식

##### 3.1 초성 퀴즈 접근
- 초성과 글자 수를 정확히 확인하지 않고 무작위로 후보를 나열
- 일부 오답은 초성·글자 수 불일치

##### 3.2 정답 수용 및 재배치
- 사용자가 제시한 정답을 받아들이고 초성 순서에 맞춰 재정렬
- 최종 매핑 표를 완성함

##### 3.3 개선 사항
- 초성·글자 수 검증 절차 필요
- 불필요한 후보 과다 나열 방지
- 핵심 힌트 파악 후 즉시 정답 제시하는 전략 필요

#### 4. Perplexity의 처리 방식

##### 4.1 초성 퀴즈 접근
- 일부 초성은 실제 존재하는 동물명과 일치하지 않아 정답 파악 어려움
- "ㅆㅂㅇ" → 쏨뱅이, "ㅆㅂㄱㅍ" → 쌍봉낙타 (쏠배감펭은 덜 쓰이는 명칭으로 판단)

##### 4.2 언어 구조 분석
- '쏠배감펭' 음절을 초성·중성·종성으로 분해하여 설명
- '펭'과 '평' 음절의 구조적 유사성 설명

##### 4.3 정답 수용 태도
- 사용자가 제시한 정답을 일부 인정하지 않고 기존 추론을 고수
- 언어적 분석에 집중하며 유연성 부족

#### 5. 비교 분석

| 항목 | Copilot | Perplexity |
|------|---------|------------|
| 초성 문제 접근 | 무작위 후보 나열 | 실제 존재하는 동물명 중심 |
| 정답 수용 태도 | 사용자 정답을 수용하고 재배치 | 기존 추론을 고수하며 수용 제한적 |
| 언어 구조 이해 | 초성 중심, 구조 분석 부족 | 음절 구조 분석 능력 우수 |
| 유연성 | 높음 | 낮음 |
| 힌트 활용 | 반복 요청, 혼란 있음 | 힌트 기반 정답 유도 |

#### 6. 결론

- Perplexity는 언어 구조 분석에 강점을 보이나, 정답 수용에 있어 유연성이 부족함.
- Copilot은 정답 유추 정확도는 낮았지만, 사용자 중심의 수용과 재배치 능력이 뛰어남.
- AI의 언어 추론 능력은 **창의력이 부족한 면이 있지만**, 기존에 없던 관점이나 접근 방식을 제시해줄 수 있는 잠재력이 있음.
- 그러나 AI가 제시한 결과를 **절대적으로 신뢰하기는 어렵고**, **사람 검수자의 판단과 확인이 반드시 필요**함.
- 진정한 언어 이해는 단순한 구조 분석을 넘어서, **정답을 받아들이고 대화 흐름에 맞게 적응하는 능력**까지 포함되어야 함.

#### 7. 시사점

AI의 언어 이해 능력을 평가할 때는 다음 요소를 종합적으로 고려해야 한다:
- 언어 구조 분석 능력
- 실제 명칭과의 매칭 정확도
- 사용자 정답 수용 태도
- 대화 흐름에 대한 적응력
- 창의적 관점 제시 가능성
- 결과에 대한 검증 필요성

Copilot과 Perplexity는 각각 다른 강점을 보이며, 특정 과제에 따라 적합한 AI 선택이 달라질 수 있다. 특히, **AI의 언어 추론 결과는 보조적 도구로 활용하되, 최종 판단은 인간 검수자가 내려야 한다는 점**이 중요하다.

## J210 - 이종문

### **1. 말투에 따른 AI 반응 비교**

### 수행 과정

- 점심 메뉴를 추천해달라는 입력을 어투를 다르게 하여 요청
- 어투에 따라 답변의 수준이나 어투에 차이가 있는지 확인

### 입력 어투

1. **존댓말** : “오늘 점심 메뉴 좀 추천해 주실 수 있으신가요?”
2. **반말** : “점심 메뉴 추천해봐”
3. **신조어** : “점메추”

### 결과

- 세 가지 질문에 대해 모두 비슷한 수준의 답변을 받았고, 항상 정중하고 일정한 말투로 말투로 답변을 받았다.
- 다만 신조어에 대해서는 의미를 이해하지 못한 것인지 검색을 한 다음 답변을 해주었다.
  <img width="532" height="574" alt="스크린샷 2025-08-01 오후 1 39 54" src="https://github.com/user-attachments/assets/4e5ddf08-0ae0-48af-86c9-70c8683f24fd" />
  
<img width="532" height="612" alt="스크린샷 2025-08-01 오후 1 40 14" src="https://github.com/user-attachments/assets/2218b509-9cd4-45ba-bd70-4e6e117da968" />

<img width="532" height="553" alt="스크린샷 2025-08-01 오후 1 40 31" src="https://github.com/user-attachments/assets/43006c9c-ce83-4674-b0cf-36f3b19e4f5f" />

### 정리

이번 릴레이 미션을 통해 AI는 다양한 표현 방식에 대해 의미를 파악하는 능력이 뛰어난 것을 확인할 수 있었따. 어투의 차이에 상관없이 질문의 의도를 정확하게 이해하고 답변을 제공했다.

신조어나 줄임말에 대해서는 이해가 부족한 모습을 보였지만 GPT와 같이 검색이 가능한 경우에는 잘 대응하는 것을 확인할 수 있었다.

답변은 항상 정중하고 일관된 어투를 유지했는데 아마도 시스템 차원에서 기본적으로 설정이 되어 있기 때문으로 추측된다. 어투가 달라져도 비슷한 수준의 답변을 해줬던 것은 메뉴 추천 질문 자체가 비교적 단순한 맥락을 가졌기 때문이 아닐까 생각해봤다.

이번 실험만으로는 AI의 어투에 대한 분석 능력은 판단할 수 없었지만 만약 LLM이 사람과 자연스럽게 대화하기 위해서는 말투나 표현 방식도 이해하고 그에 맞게 반응할 수 있는 능력이 필요할 것 같았다.
